# deep-learning-image-caption
A paper list of image caption

## 2019
* ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks [[pdf](https://arxiv.org/pdf/1908.02265v1.pdf)] [[code](https://github.com/jiasenlu/vilbert_beta)]


## 2018
* Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering | [**CVPR 2018**] [[pdf](https://arxiv.org/pdf/1707.07998v3.pdf)] [[code](https://github.com/facebookresearch/pythia)]

## 2017

## 2016

## 2015
* Show, Attend and Tell: Neural Image Caption Generation with Visual Attention [[pdf](https://arxiv.org/pdf/1502.03044v3.pdf)] [[code](https://github.com/kelvinxu/arctic-captions)]


# 
# Data sets paper

* Li X, Lan W, Dong J, et al. Adding Chinese captions to images[C]//Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval. ACM, 2016: 271-275.
* Wu J, Zheng H, Zhao B, et al. AI challenger: a large-scale dataset for going deeper in image understanding[J]. arXiv preprint arXiv:1711.06475, 2017.
* Xirong Li, Chaoxi Xu, Xiaoxu Wang, Weiyu Lan, Zhengxiong Jia, Gang Yang, Jieping Xu, COCO-CN for Cross-Lingual Image Tagging, Captioning and Retrieval, IEEE Transactions on Multimedia, Volume 21, Number 9, pages 2347-2360, 2019
